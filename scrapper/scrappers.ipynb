{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "USER_DATA = {\n",
    "    'user': 'postgres',\n",
    "    'password': 'admin'\n",
    "}\n",
    "\n",
    "BD_DATA = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'tablegames',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "def get_psycopg2_connection(user_data, db_data):\n",
    "    \"\"\"\n",
    "    Entrega una conexión a la base de datos presente en db_data,\n",
    "    considerando el usuario en user_data\n",
    "\n",
    "    :param user_data: Diccionario con los datos de conexión del usuario\n",
    "    :param db_data: Diccionario con los datos de conexión de la base de datos\n",
    "    :return: psycopg2 connection\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(user=user_data['user'],\n",
    "                                password=user_data['password'],\n",
    "                                host=db_data['host'],\n",
    "                                port=db_data['port'],\n",
    "                                database=db_data['database'])\n",
    "        return conn\n",
    "    except Exception as error:\n",
    "        print(\"Error al conectarse a la BD \\n {}\".format(error))\n",
    "        return None\n",
    "    \n",
    "def do_sql_upsert(user_data, db_data, upsert_query):\n",
    "    \"\"\"\n",
    "\n",
    "    :param user_data: Diccionario con los datos de conexión del usuario\n",
    "    :param db_data: Diccionario con los datos de conexión de la bd\n",
    "    :param upsert_query: Upsert Query\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = get_psycopg2_connection(user_data, db_data)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(upsert_query)\n",
    "        conn.commit()\n",
    "        return True\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\n",
    "            \"Error en do_sql_upsert: {}\".format(\n",
    "                repr(error)\n",
    "            )\n",
    "        )\n",
    "        return None\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "def get_sql_alchemy_engine(user_data, db_data):\n",
    "    \"\"\"\n",
    "        Retorna una engine de SqlAlchemy\n",
    "\n",
    "    :param user_data: Diccionario con los datos del usuario\n",
    "    :param db_data: Diccionario con los datos de la base de datos\n",
    "    :return: Sqlalchemy Engine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            URL(\n",
    "                'postgresql+psycopg2',\n",
    "                username=user_data['user'],\n",
    "                password=user_data['password'],\n",
    "                host=db_data['host'],\n",
    "                port=db_data['port'],\n",
    "                database=db_data['database']\n",
    "            )\n",
    "        )\n",
    "        return engine\n",
    "    except Exception as error:\n",
    "        print(\"Error al generar un engine: {}\".format(repr(error)))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES_UPSERT = '''\n",
    "\n",
    "INSERT INTO public.games(\n",
    "        permalink,\n",
    "        title,\n",
    "        price,\n",
    "        image,\n",
    "        url,\n",
    "        description)\n",
    "    VALUES {} \n",
    "    ON CONFLICT ON CONSTRAINT games_pkey \n",
    "        DO UPDATE \n",
    "        SET price = EXCLUDED.price,\n",
    "            url = EXCLUDED.url,\n",
    "            description = EXCLUDED.description\n",
    "'''\n",
    "\n",
    "PRICES_INSERT = '''\n",
    "INSERT INTO public.price(\n",
    "        permalink,\n",
    "        date,\n",
    "        price)\n",
    "        VALUES {}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "        \n",
    "    def upsert_games(self,upsert_query):\n",
    "        try:\n",
    "            df_aux = self.df[['permalink','title','price','image','url','description']]\n",
    "            values = [\n",
    "                # reemplazar \" por ' para casos con ' en el email\n",
    "                \"{}\".format(value).replace(r'\"', r\"'\")\n",
    "                if value else 'NULL'\n",
    "                for value in df_aux.itertuples(\n",
    "                    index=False,\n",
    "                    name=None)\n",
    "            ]\n",
    "            if do_sql_upsert(\n",
    "                USER_DATA,\n",
    "                BD_DATA,\n",
    "                upsert_query.format(\n",
    "                    ','.join(values).replace('None', 'NULL')\n",
    "                )  # Es necesario reemplazar None por NULL en la consulta\n",
    "            ):\n",
    "                print(\n",
    "                    \"Juegos insertados y/o actualizados\")\n",
    "            else:\n",
    "                raise Exception('Error en do_sql_upsert')\n",
    "        except Exception as error:\n",
    "            print(\n",
    "                \"Error en upload_data: {}\".format(\n",
    "                    repr(error)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    def insert_price(self,insert_query):\n",
    "        try:\n",
    "            self.df.date = self.df.date.astype(str)\n",
    "            df_aux = self.df[['permalink','date','price']]\n",
    "            \n",
    "            values = [\n",
    "                # reemplazar \" por ' para casos con ' en el email\n",
    "                \"{}\".format(value).replace(r'\"', r\"'\")\n",
    "                if value else 'NULL'\n",
    "                for value in df_aux.itertuples(\n",
    "                    index=False,\n",
    "                    name=None)\n",
    "            ]\n",
    "            \n",
    "            if do_sql_upsert(\n",
    "                USER_DATA,\n",
    "                BD_DATA,\n",
    "                insert_query.format(\n",
    "                    ','.join(values).replace('None', 'NULL')\n",
    "                )):\n",
    "                print(\n",
    "                    \"Precios insertados\")\n",
    "            else:\n",
    "                raise Exception('Error en do_sql_upsert')\n",
    "        except Exception as error:\n",
    "            print('Error en insert_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Juegos insertados y/o actualizados\n",
      "Precios insertados\n"
     ]
    }
   ],
   "source": [
    "devir_dataloader = DataLoader(df_devir_clean)\n",
    "devir_dataloader.upsert_games(GAMES_UPSERT)\n",
    "devir_dataloader.insert_price(PRICES_INSERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkyshipScrapper:\n",
    "    def __init__(self,base_url='https://tienda.skyship.cl/22-juegos-de-tablero'):\n",
    "        self.base_url = base_url\n",
    "        self.board_game_list = list()\n",
    "    \n",
    "    def get_next_page_url(self,page_url='https://tienda.skyship.cl/22-juegos-de-tablero'):\n",
    "        try:\n",
    "            if page_url == self.base_url:\n",
    "                url = urllib.request.urlopen(\n",
    "                    \"{}\".format(\n",
    "                        self.base_url\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                url = urllib.request.urlopen(\n",
    "                    \"{}\".format(page_url)\n",
    "                )\n",
    "            soup = BeautifulSoup(url,'html.parser')\n",
    "            next_url = soup.find(\n",
    "                \"a\",\n",
    "                {\"class\":\"next page-numbers\"}\n",
    "            ).get('href')\n",
    "            return next_url\n",
    "        except AttributeError as error:\n",
    "            print('hola')\n",
    "            return None\n",
    "        except Exception as error:\n",
    "            print(\n",
    "                \"Error al obtener la siguiente página: {}\".format(\n",
    "                    repr(error)\n",
    "                )\n",
    "            )\n",
    "            return None\n",
    "    \n",
    "    def get_products_url(self,page_url):\n",
    "        try:\n",
    "            url = urllib.request.urlopen(\n",
    "                \"{}\".format(page_url)\n",
    "            )\n",
    "            soup = BeautifulSoup(url,'html.parser')\n",
    "            products_url = [url.get('href') for url in soup.find_all(href=re.compile(\"/producto/\"))]\n",
    "            return list(set(products_url))\n",
    "        except Exception as error:\n",
    "            print(\n",
    "                \"Error en get_products_url: {}\".format(\n",
    "                    repr(error)\n",
    "                )\n",
    "            )\n",
    "            return None\n",
    "    \n",
    "    def get_product_info(self,page_url):\n",
    "        try:\n",
    "            url = urllib.request.urlopen(\n",
    "                '{}'.format(\n",
    "                    page_url\n",
    "                )\n",
    "            )\n",
    "            soup = BeautifulSoup(url,'html.parser')\n",
    "            \n",
    "            #delete strong tags\n",
    "            for tag in soup.find_all('strong'):\n",
    "                tag.replaceWith('')\n",
    "            for tag in soup.find_all('b'):\n",
    "                tag.replaceWith('')\n",
    "            for tag in soup.find_all('i'):\n",
    "                tag.replaceWith('')\n",
    "            for tag in soup.find_all('em'):\n",
    "                tag.replaceWith('')\n",
    "                \n",
    "            product_dict = dict()\n",
    "            \n",
    "            #get image\n",
    "            image_div = soup.find('div',{'class':'woocommerce-product-gallery__image'})\n",
    "            product_dict['image'] = image_div.a.contents[0].get('data-large_image')\n",
    "            \n",
    "            #get title and price\n",
    "            summary_div = soup.find('div',{'class':'summary entry-summary'})\n",
    "            product_dict['title'] = summary_div.h1.contents[0]\n",
    "            product_dict['price'] = summary_div.findAll('p',{'class':'pvrp'})[1].contents[0]\n",
    "            \n",
    "            #get description\n",
    "            description_div = soup.find(\n",
    "                'div',\n",
    "                {'id':'tab-description'}\n",
    "            )\n",
    "            \n",
    "            if description_div != None:\n",
    "                description_p = [\n",
    "                    description.contents[0] \n",
    "                    for description in description_div.findAll('p') \n",
    "                    if (not description.find('span')) and (not description.find('a')) and (not description.find('iframe'))\n",
    "                ] \n",
    "\n",
    "\n",
    "                product_dict['description'] = '\\n '.join(description_p)\n",
    "            else:\n",
    "                product_dict['description'] = 'Descripción no proporcionada.'\n",
    "            product_dict['url'] = page_url\n",
    "            \n",
    "            self.board_game_list.append(product_dict)\n",
    "        except Exception as error:\n",
    "            print(page_url)\n",
    "            print(error)\n",
    "            \n",
    "    def recursive_scrapper(self,page_url):\n",
    "        urls = self.get_products_url(page_url)\n",
    "        for product_url in urls:\n",
    "            self.get_product_info(product_url)\n",
    "        next_url = self.get_next_page_url(page_url)\n",
    "        if next_url:\n",
    "            print(\"Next Page: {}\".format(next_url))\n",
    "            return self.recursive_scrapper(next_url)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "    def get_contents(self):\n",
    "        try:\n",
    "            self.recursive_scrapper(self.base_url)\n",
    "            df = pd.DataFrame(self.board_game_list)\n",
    "            df['date'] = datetime.datetime.today()\n",
    "            return df\n",
    "        except Exception as error:\n",
    "            print(\n",
    "                \"Error en get_context: {}\".format(\n",
    "                    repr(error)\n",
    "                )\n",
    "            )\n",
    "            return None\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "skyship_scrapper = SkyshipScrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "df_skyship = skyship_scrapper.get_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_skyship.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
